{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql.functions import from_unixtime, when, col, lit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext('local')\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? n\n",
      "Nothing done.\n",
      "SparkSQL sesssion created\n"
     ]
    }
   ],
   "source": [
    "%reset\n",
    "import pyspark.sql\n",
    "session = pyspark.sql.SparkSession.builder \\\n",
    "    .master('spark://10.64.22.198:7077') \\\n",
    "    .appName('Demo') \\\n",
    "    .config('spark.jars.packages','org.diana-hep:spark-root_2.11:0.1.16,org.diana-hep:histogrammar-sparksql_2.11:1.0.4') \\\n",
    "    .config('spark.driver.extraClassPath','/opt/hadoop/share/hadoop/common/lib/EOSfs.jar') \\\n",
    "    .config('spark.executor.extraClassPath','/opt/hadoop/share/hadoop/common/lib/EOSfs.jar') \\\n",
    "    .config('py-files','helper.py') \\\n",
    "    .getOrCreate()\n",
    "    \n",
    "sqlContext = session\n",
    "\n",
    "print('SparkSQL sesssion created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "from samples_tthml import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../Files/ttH_Multilep/ mc16_13TeV.aMcAtNloPythia8EvtGen_ttH_r9364_p3832.csv\n",
      "../../Files/ttH_Multilep/ mc16_13TeV.Sherpa_221_NN30NNLO_ttW_multilegNLO_r9364_p3830.csv\n"
     ]
    }
   ],
   "source": [
    "for s in samples:\n",
    "    print(BASE,samples[s]['filename'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ttH sample file \n",
      " ../../Files/ttH_Multilep/mc16_13TeV.aMcAtNloPythia8EvtGen_ttH_r9364_p3832.csv\n",
      "Loading ttW sample file \n",
      " ../../Files/ttH_Multilep/mc16_13TeV.Sherpa_221_NN30NNLO_ttW_multilegNLO_r9364_p3830.csv\n"
     ]
    }
   ],
   "source": [
    "DFList = [] \n",
    "\n",
    "for s in samples:\n",
    "    dsPath = BASE+samples[s]['filename']\n",
    "    print('Loading {0} sample file'.format(s),'\\n',dsPath )   \n",
    "    tempDF =     spark.read\\\n",
    "                .format('csv')\\\n",
    "                .option('header', 'true')\\\n",
    "                .option('inferschema', 'true')\\\n",
    "                .load(dsPath)\n",
    "    tempDF=tempDF.withColumn(\"sample\", lit(s)) \n",
    "    DFList.append(tempDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- entry: integer (nullable = true)\n",
      " |-- DEtall01: double (nullable = true)\n",
      " |-- lep_flavour: integer (nullable = true)\n",
      " |-- max_eta: double (nullable = true)\n",
      " |-- minDeltaR_LJ_0: double (nullable = true)\n",
      " |-- minDeltaR_LJ_1: double (nullable = true)\n",
      " |-- Meff: double (nullable = true)\n",
      " |-- DRlj00: double (nullable = true)\n",
      " |-- min_DRl0b: double (nullable = true)\n",
      " |-- min_DRlj_new: double (nullable = true)\n",
      " |-- DPhij0MET: double (nullable = true)\n",
      " |-- lead_BjetPt: double (nullable = true)\n",
      " |-- lead_jet_sumBEff: double (nullable = true)\n",
      " |-- sublead_jet_sumBEff: double (nullable = true)\n",
      " |-- scale_nom: double (nullable = true)\n",
      " |-- pileupEventWeight_090: double (nullable = true)\n",
      " |-- MV2c10_70_EventWeight: double (nullable = true)\n",
      " |-- JVT_EventWeight: double (nullable = true)\n",
      " |-- SherpaNJetWeight: double (nullable = true)\n",
      " |-- EventNumber: integer (nullable = true)\n",
      " |-- RunYear: integer (nullable = true)\n",
      " |-- MET_RefFinal_et: double (nullable = true)\n",
      " |-- lep_Pt_0: double (nullable = true)\n",
      " |-- lep_Eta_0: double (nullable = true)\n",
      " |-- lep_Phi_0: double (nullable = true)\n",
      " |-- lep_Pt_1: double (nullable = true)\n",
      " |-- lep_Eta_1: double (nullable = true)\n",
      " |-- lep_Phi_1: double (nullable = true)\n",
      " |-- total_charge: integer (nullable = true)\n",
      " |-- Mll01: double (nullable = true)\n",
      " |-- Ptll01: double (nullable = true)\n",
      " |-- DRll01: double (nullable = true)\n",
      " |-- nJets_OR_T: integer (nullable = true)\n",
      " |-- nJets_OR_T_MV2c10_70: integer (nullable = true)\n",
      " |-- HT_lep: double (nullable = true)\n",
      " |-- HT_jets: double (nullable = true)\n",
      " |-- lead_jetPt: double (nullable = true)\n",
      " |-- sublead_jetPt: double (nullable = true)\n",
      " |-- lepSFTrigTight: double (nullable = true)\n",
      " |-- lepSFObjTight: double (nullable = true)\n",
      " |-- weightS: double (nullable = true)\n",
      " |-- sample: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DFList[0].printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 69902 events\n"
     ]
    }
   ],
   "source": [
    "total_events = DFList[0].count()\n",
    "print('There are',total_events,'events')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DEtall01',\n",
       " 'lep_flavour',\n",
       " 'max_eta',\n",
       " 'minDeltaR_LJ_0',\n",
       " 'minDeltaR_LJ_1',\n",
       " 'Meff',\n",
       " 'DRlj00',\n",
       " 'min_DRl0b',\n",
       " 'min_DRlj_new',\n",
       " 'DPhij0MET',\n",
       " 'lead_BjetPt',\n",
       " 'lead_jet_sumBEff',\n",
       " 'sublead_jet_sumBEff',\n",
       " 'MET_RefFinal_et',\n",
       " 'lep_Pt_0',\n",
       " 'lep_Eta_0',\n",
       " 'lep_Phi_0',\n",
       " 'lep_Pt_1',\n",
       " 'lep_Eta_1',\n",
       " 'lep_Phi_1',\n",
       " 'total_charge',\n",
       " 'Mll01',\n",
       " 'Ptll01',\n",
       " 'DRll01',\n",
       " 'nJets_OR_T',\n",
       " 'nJets_OR_T_MV2c10_70',\n",
       " 'HT_lep',\n",
       " 'HT_jets',\n",
       " 'lead_jetPt',\n",
       " 'sublead_jetPt',\n",
       " 'sample']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../VarList_30.json\") as vardict:\n",
    "    variablelist = json.load(vardict)[:]\n",
    "    \n",
    "variablelist.append(\"sample\")\n",
    "variablelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DEtall01: double (nullable = true)\n",
      " |-- lep_flavour: integer (nullable = true)\n",
      " |-- max_eta: double (nullable = true)\n",
      " |-- minDeltaR_LJ_0: double (nullable = true)\n",
      " |-- minDeltaR_LJ_1: double (nullable = true)\n",
      " |-- Meff: double (nullable = true)\n",
      " |-- DRlj00: double (nullable = true)\n",
      " |-- min_DRl0b: double (nullable = true)\n",
      " |-- min_DRlj_new: double (nullable = true)\n",
      " |-- DPhij0MET: double (nullable = true)\n",
      " |-- lead_BjetPt: double (nullable = true)\n",
      " |-- lead_jet_sumBEff: double (nullable = true)\n",
      " |-- sublead_jet_sumBEff: double (nullable = true)\n",
      " |-- MET_RefFinal_et: double (nullable = true)\n",
      " |-- lep_Pt_0: double (nullable = true)\n",
      " |-- lep_Eta_0: double (nullable = true)\n",
      " |-- lep_Phi_0: double (nullable = true)\n",
      " |-- lep_Pt_1: double (nullable = true)\n",
      " |-- lep_Eta_1: double (nullable = true)\n",
      " |-- lep_Phi_1: double (nullable = true)\n",
      " |-- total_charge: integer (nullable = true)\n",
      " |-- Mll01: double (nullable = true)\n",
      " |-- Ptll01: double (nullable = true)\n",
      " |-- DRll01: double (nullable = true)\n",
      " |-- nJets_OR_T: integer (nullable = true)\n",
      " |-- nJets_OR_T_MV2c10_70: integer (nullable = true)\n",
      " |-- HT_lep: double (nullable = true)\n",
      " |-- HT_jets: double (nullable = true)\n",
      " |-- lead_jetPt: double (nullable = true)\n",
      " |-- sublead_jetPt: double (nullable = true)\n",
      " |-- sample: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select columns from dataframe\n",
    "DF = DFList[0].select(variablelist)\n",
    "DF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partitions: 2\n"
     ]
    }
   ],
   "source": [
    "# Merge all dataset into a single dataframe\n",
    "for df_ in DFList[1:]:\n",
    "    DF = DF.union(df_.select(variablelist))\n",
    "\n",
    "print( 'Partitions: {}'.format(DF.rdd.getNumPartitions()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of events in the DataFrame  =  156656\n",
      "events in the DataFrame with \"nJets_OR_T > 5\" =  38368\n"
     ]
    }
   ],
   "source": [
    "print('total number of events in the DataFrame  = ', DF.count())\n",
    "print( 'events in the DataFrame with \\\"nJets_OR_T > 5\\\" = ', DF.filter('nJets_OR_T > 5').count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cach dataframe into memory, shared across the Spark cluster nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = DF.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+---------+-----------+-----------+------------+\n",
      "|sample|nJets_OR_T| lep_Pt_0|  lep_Eta_0|  lep_Phi_0|total_charge|\n",
      "+------+----------+---------+-----------+-----------+------------+\n",
      "|   ttH|         6| 65184.87|  1.3295902|   2.048432|          -2|\n",
      "|   ttH|         5|40491.316|-0.41755068|-0.65665025|           2|\n",
      "|   ttH|         4| 80014.03|0.043774348| -1.9746306|          -2|\n",
      "|   ttH|         5|35063.797|  1.3237612|   3.133612|           2|\n",
      "|   ttH|         7| 45864.24|  1.9134886| -1.6473318|           2|\n",
      "+------+----------+---------+-----------+-----------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DF.filter(DF['sample'] == 'ttH')\\\n",
    "  .select('sample','nJets_OR_T','lep_Pt_0','lep_Eta_0','lep_Phi_0','total_charge')\\\n",
    "  .show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
